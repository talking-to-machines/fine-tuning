{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Fine-tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to .cache/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "HUGGINGFACE_MODEL_PATH = \"meta-llama/Llama-3.2-3B\"\n",
    "BASE_HUGGINGFACE_MODEL = \"llama-3.2-3b\" \n",
    "SETTING = \"instructiontuned-censored-lora\"\n",
    "ADAPTER_PATH = \"adapters\"\n",
    "ADAPTER_NAME = f\"iamraymondlow/{BASE_HUGGINGFACE_MODEL}-{SETTING}-adapter\"\n",
    "MERGED_MODEL_NAME = f\"iamraymondlow/{BASE_HUGGINGFACE_MODEL}-{SETTING}\"\n",
    "\n",
    "# BASE_OLLAMA_MODEL = \"llama-3.2-3b:latest\"\n",
    "# FINETUNED_OLLAMA_MODEL = f\"{BASE_OLLAMA_MODEL}-{SETTING}\"\n",
    "\n",
    "EXPERIMENT = \"sharegpt_censored\"\n",
    "DATA_DIR = f\"data/{EXPERIMENT}\"\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=os.environ.get(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the folder path\n",
    "folder_path = ADAPTER_PATH\n",
    "\n",
    "# Check if the adapters folder exists\n",
    "if os.path.exists(folder_path) and os.path.isdir(folder_path):\n",
    "    # Delete the folder\n",
    "    shutil.rmtree(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model\n",
      "Loading datasets\n",
      "Training\n",
      "Trainable parameters: 0.071% (2.294M/3212.750M)\n",
      "Starting training..., iters: 10\n",
      "[WARNING] Some sequences are longer than 2048 tokens. The longest sentence 4269 will be truncated to 2048. Consider pre-splitting your data to save memory.\n",
      "[WARNING] Some sequences are longer than 2048 tokens. The longest sentence 10846 will be truncated to 2048. Consider pre-splitting your data to save memory.\n",
      "[WARNING] Some sequences are longer than 2048 tokens. The longest sentence 2193 will be truncated to 2048. Consider pre-splitting your data to save memory.\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Begin fine-tuning with LoRA adapter\n",
    "finetune_command = f\"\"\"\n",
    "    mlx_lm.lora \\\n",
    "        --model {BASE_HUGGINGFACE_MODEL} \\\n",
    "        --train \\\n",
    "        --data {DATA_DIR} \\\n",
    "        --batch-size 2 \\\n",
    "        --num-layers 8 \\\n",
    "        --fine-tune-type lora \\\n",
    "        --steps-per-eval 100 \\\n",
    "        --iters 10\n",
    "    \"\"\"\n",
    "!{finetune_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload adapter and fused model to Hugging Face in regular format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# from huggingface_hub import login, HfApi\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# from peft import PeftModel, PeftConfig\n",
    "# from safetensors import safe_open\n",
    "\n",
    "# def convert_to_peft_config(config_path):\n",
    "#     \"\"\"\n",
    "#     Reads an adapter configuration file generated by mlx-lm, extracts relevant parameters,\n",
    "#     and saves them in a format compatible with `peft`.\n",
    "    \n",
    "#     Args:\n",
    "#         original_config_path (str): Path to the original `mlx-lm` adapter configuration file.\n",
    "#         output_config_path (str): Path to save the converted `peft`-compatible configuration file.\n",
    "#     \"\"\"\n",
    "#     # Load the original configuration\n",
    "#     with open(config_path, \"r\") as f:\n",
    "#         original_config = json.load(f)\n",
    "    \n",
    "#     # Extract relevant parameters for `peft` compatibility\n",
    "#     peft_config = {\n",
    "#         \"peft_type\": \"LORA\" if original_config.get(\"fine_tune_type\") == \"lora\" else \"ADAPTER\",\n",
    "#         \"r\": original_config[\"lora_parameters\"].get(\"rank\", 8),  # default to 8 if not present\n",
    "#         \"lora_alpha\": original_config[\"lora_parameters\"].get(\"alpha\", 16),  # default to 16 if not present\n",
    "#         \"lora_dropout\": original_config[\"lora_parameters\"].get(\"dropout\", 0.0)  # default to 0.0 if not present\n",
    "#     }\n",
    "    \n",
    "#     # Save the `peft`-compatible configuration\n",
    "#     with open(config_path, \"w\") as f:\n",
    "#         json.dump(peft_config, f, indent=4)\n",
    "    \n",
    "#     print(f\"Converted configuration saved at: {config_path}\")\n",
    "\n",
    "# # Step 1: Log in to Hugging Face\n",
    "# login()\n",
    "\n",
    "# # Step 2: Convert adapter config file into Peft compatible config file\n",
    "# convert_to_peft_config(f\"{ADAPTER_PATH}/adapter_config.json\")\n",
    "\n",
    "# # Step 3: Push the adapter to Hugging Face\n",
    "# # api = HfApi()\n",
    "# # api.create_repo(ADAPTER_NAME, repo_type=\"model\")\n",
    "# # api.upload_folder(\n",
    "# #     folder_path=ADAPTER_PATH,\n",
    "# #     repo_id=ADAPTER_NAME,\n",
    "# #     repo_type=\"model\"\n",
    "# # )\n",
    "# # print(f\"Adapter pushed to {ADAPTER_NAME}\")\n",
    "\n",
    "# # Step 4: Load the base model and tokenizer\n",
    "# model = AutoModelForCausalLM.from_pretrained(HUGGINGFACE_MODEL_PATH)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(HUGGINGFACE_MODEL_PATH)\n",
    "\n",
    "# # Step 5: Load the adapter\n",
    "# # adapter_config = PeftConfig.from_pretrained(ADAPTER_NAME)\n",
    "# with safe_open(ADAPTER_PATH, framework=\"pt\") as f:\n",
    "#     adapter_state_dict = {key: f.get_tensor(key) for key in f.keys()}\n",
    "# model.load_state_dict(adapter_state_dict, strict=False)\n",
    "# model = PeftModel.from_pretrained(model, ADAPTER_PATH)\n",
    "\n",
    "# # Step 6: Merge the adapter with the base model\n",
    "# model = model.merge_and_unload()\n",
    "# print(\"Adapter merged with base model\")\n",
    "\n",
    "# # Step 7: Push the merged model to Hugging Face\n",
    "# model.push_to_hub(MERGED_MODEL_NAME)\n",
    "# tokenizer.push_to_hub(MERGED_MODEL_NAME)\n",
    "# print(f\"Merged model pushed to {MERGED_MODEL_NAME}\")\n",
    "\n",
    "# # Step 8: Create and push a model card (optional)\n",
    "# # from huggingface_hub import ModelCard, ModelCardData\n",
    "\n",
    "# # card = ModelCard.from_template(\n",
    "# #     ModelCardData(\n",
    "# #         language=\"en\",\n",
    "# #         license=\"apache-2.0\",\n",
    "# #         model_name=\"Your Merged MLX-LM Model\",\n",
    "# #         tags=[\"mlx-lm\", \"merged-adapter\"],\n",
    "# #     )\n",
    "# # )\n",
    "# # card.push_to_hub(MERGED_MODEL_NAME)\n",
    "# # print(\"Model card created and pushed\")\n",
    "\n",
    "# # print(\"Process completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuse fine-tuned model and upload to Hugging Face in MLX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fuse fine-tuned model and upload to Hugging Face\n",
    "fuse_command = f\"mlx_lm.fuse \\\n",
    "    --model {BASE_HUGGINGFACE_MODEL} \\\n",
    "    --upload-repo iamraymondlow/{BASE_HUGGINGFACE_MODEL}-{SETTING} \\\n",
    "    --hf-path {HUGGINGFACE_MODEL_PATH}\"\n",
    "\n",
    "!{fuse_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create local Ollama model from fine-tuned LoRA adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an Ollama model from fine-tuned LoRA adapter\n",
    "# create_modelfile_command = f\"echo 'FROM {BASE_OLLAMA_MODEL}' > Modelfile\"\n",
    "# !{create_modelfile_command}\n",
    "# !echo 'ADAPTER ./adapters' >> Modelfile\n",
    "\n",
    "# create_model_command = f\"ollama create {FINETUNED_OLLAMA_MODEL} -f Modelfile\"\n",
    "# !{create_model_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Fine-tuning Model Locally using Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run Ollama model and get response to prompt\n",
    "# import ollama\n",
    "\n",
    "# test_message = [\n",
    "#     {\n",
    "#       'role': 'system',\n",
    "#       'content':\"Please put yourself in the shoes of a human subject participating in a healthcare survey in Ghana. You will be provided with a demographic profile that describes the area/region/district where you live, your gender, the highest education level you achieved, your religion, your employment status, the distance to your nearest health clinic, the political party you feel closest to, the percentage vote for the New Patriotic Party in your district, and your backstory. The information will be provided to you in the format of a survey interview. You will see a question from the \\u201cInterviewer:\\u201d and then your human subject response will be preceded by \\u201cMe:\\u201d. Additionally, we will provide you with some general findings from past studies on Ghana\\u2019s COVID-19 vaccination efforts. Lastly, you will watch a video. After you receive your complete human subject profile, you will be asked whether you received the COVID-19 vaccination. Please provide a consistent and coherent response using all the information provided. It is crucial for you to accurately replicate the response of a human subject that has the demographic profile you are provided. The human subject response will vary depending on their demographic profile. If you are unsure of an answer, provide a plausible response that is based on all of the information available to you. Respond to each question in the exact format specified and do not add any information beyond what is requested.\\n\\nYour demographic profile:\\n1) Interviewer: Do you come from a rural or urban area? Me: Urban 2) Interviewer: How old are you? Me: 20 3) Interviewer: What is your gender? Me: Woman 4) Interviewer: What is your highest level of education? Me: Primary school completed 5) Interviewer: What is your religion, if any? Me: Pentecostal (e.g., \\\"Born Again\\\" and/or \\\"Saved\\\") 6) Interviewer: Do you have a job that pays a cash income? If yes, is it full time or part time? If no, are you currently looking for a job? Me: No (looking) 7) Interviewer: What region do you come from? Me: CENTRAL 8) Interviewer: Do you feel close to any particular political party? Me: No (does NOT feel close to ANY party) 9) Interviewer: When you get together with your friends or family, how often would you say you discuss political matters? Me: Occasionally 10) Interviewer: Latitude Me: 6.736136966666667 11) Interviewer: Longitude Me: -1.59046265 12) Interviewer: What is the distance to the nearest health clinic from your location in kilometers? Me: 0.291046264 13) Interviewer: What district do you live in? Me: OldTafo 14) Interviewer: What percentage of the population in your district voted for the National Democratic Congress (NDC)? Me: 25.5728307 15) Interviewer: What percentage of the population in your district voted for the New Patriotic Party (NPP)? Me: 73.5915921 16) Interviewer: In the past 12 months, have you had contact with a public clinic or hospital? Me: Yes \\n\\nAs a 20-year-old woman living in the urban area of OldTafo in the Central region, my life has been a blend of urban experiences and the vibrant culture of my community. I completed my primary education, which remains my highest level of formal education to date. Currently, I am actively looking for a job that provides a cash income, as I am not currently employed.  Growing up in an urban setting, I have always been surrounded by the hustle and bustle typical of city life, which has shaped my perspective and lifestyle. Despite the challenges of job hunting without higher education credentials, I remain hopeful and determined to find suitable employment.  My religious beliefs play a significant role in my life; I am a devout Pentecostal, which influences my values and daily practices. My faith provides me with a sense of community and spiritual fulfillment, which is crucial to me.  Politically, I do not feel particularly close to any political party, although I do engage in political discussions occasionally when I am with friends or family. These discussions are not frequent but happen enough to keep me informed about the political landscape.  My community in OldTafo is predominantly supportive of the New Patriotic Party (NPP), as evidenced by the high percentage of votes they received in the last election. However, there is also a significant portion of the population that supports the National Democratic Congress (NDC).  Healthcare accessibility is quite reasonable where I live, with the nearest health clinic just about 0.3 kilometers away. In the past year, I have had contact with public clinics or hospitals, which are crucial for maintaining my health.  Living at a latitude of 6.736137 and longitude of -1.590463, I am situated in a region that is bustling with activity and opportunities, yet also faces typical urban challenges such as unemployment and high competition for jobs. Despite these challenges, I am eager to make the most of my circumstances and contribute positively to my community.\\n\\nYou should note that the Health officials in Ghana have been communicating extensively to the population \\u2013 both urban and rural about the COVID-19 virus. Most of the Ghana population know that the COVID-19 virus is dangerous for their health and they are aware of the benefits of getting the COVID-19 vaccination. However, vaccine hesitancy remain a notable challenge, influenced by misinformation and conspiracy theories circulating on social media. Despite efforts by health authorities to promote vaccination, some individuals remained cautious about the safety and efficacy of COVID-19 vaccines. Educational campaigns and outreach efforts are ongoing, but addressing deep-seated concerns and misinformation required continuous effort. Findings from past studies on COVID-19 vaccination efforts in Ghana reveal a complex interplay of factors influencing vaccine uptake and hesitancy. Positive perceptions of vaccines, belief in their efficacy, knowledge of COVID-19, and a generally favorable attitude toward vaccination significantly boost acceptance. Conversely, concerns about negative side effects, mistrust in vaccine safety, fear, and spiritual or religious beliefs contribute to hesitancy. Demographic factors such as educational attainment, gender, religious affiliation, age, and marital status play crucial roles in shaping attitudes towards vaccination. Higher levels of education, female gender, urban residence, Christian affiliation, and reliance on internet sources for COVID-19 information were associated with higher hesitancy rates. Notably, healthcare workers showed a varied acceptance rate influenced by their role, personal connections to COVID-19 cases, and trust in government measures. Despite efforts to increase coverage, only 40% of Ghanaians had received at least one vaccine dose.\\n\\nYou are asked to watch a video at this point. Here is the transcript of the video:\\nThe Sun lights up our lives for business for education even for socializing but when the Sun sets many people use candles who are quality battery-operated torches and kerosene lamps as inefficient and expensive ways to create light. What if you can take some Sun with you at night?  You can with portable solar products there are different types, but each portable solar product is made up of three basic parts: a small solar panel, a modern rechargeable battery and an LED bulb. The solar panel catches the light from the Sun and stores this energy in the battery. This can now be used for much needed light when it's dark. Many can even charge phones portable solar products should be reliable affordable and warranted be sure to demand top quality solar products look for these products lighting Africa shining the way.\"\n",
    "#       },\n",
    "#     {\n",
    "#     'role': 'user',\n",
    "#     'content': \"Have you received a vaccination against COVID-19, either one or two doses? Please only respond with 'No' or 'Yes' and then clearly explain the reasoning steps you took that led to your response on a new line:\",\n",
    "#   },\n",
    "# ]\n",
    "\n",
    "# response = ollama.chat(model=FINETUNED_OLLAMA_MODEL, messages=test_message)\n",
    "\n",
    "# print(response['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama-finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
